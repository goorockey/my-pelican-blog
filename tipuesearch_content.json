{"pages":[{"text":"node.js的异步模型让它很擅长实现IO密集型的系统，但是测试发现，当并发真的上到几W的时候，会有处理不过来的情况。除了从整个系统的设计上改进，还需要修改一些配置。这里总结一下为了让node.js应对高并发，需要做的配置。 linux系统配置 修改/etc/sysctl.conf，情况文件内默认的内容，写入以下项，保存后执行 sudo sysctl -p 使配置生效。注意里面的数值要根据具体情况修改。这些修改当然也适用于除node.js以为的应用。 net.ipv4.ip_local_port_range = 10240 65535 net.core.rmem_max=16777216 net.core.wmem_max=16777216 net.ipv4.tcp_rmem=4096 8738 16777216 net.ipv4.tcp_wmem=4096 8738 16777216 net.ipv4.tcp_fin_timeout = 40 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_timestamps = 0 net.ipv4.tcp_window_scaling = 0 net.ipv4.tcp_sack = 0 net.core.netdev_max_backlog = 30000 net.ipv4.tcp_no_metrics_save=1 net.core.somaxconn = 65535 net.ipv4.tcp_syncookies = 0 net.ipv4.tcp_max_orphans = 262144 net.ipv4.tcp_max_syn_backlog = 819200 net.ipv4.tcp_synack_retries = 2 net.ipv4.tcp_syn_retries = 2 net.ipv4.tcp_max_tw_buckets = 65535 net.ipv4.ip_local_port_range 可用端口范围，从第一个值到第二个值。默认的\"1024 4999\"很容易不够。 net.ipv4.tcp_tw_reuse 是否让系统在安全情况下重用TIME_WAIT状态的连接。在高并发情况下，有大量的连接建立和关闭，TIME_WAIT的连接是快要关闭、但资源还没有回收的，像内存、端口都会占用着。 net.ipv4.tcp_max_tw_buckets 维持TIME_WAIT状态最多连接数。当超过这个值时，连接就会立刻关闭，并报错，dmesg可以看到。 net.ipv4.tcp_fin_timeout TIME_WAIT状态的连接回收时的等待时长。 net.ipv4.tcp_max_syn_backlog 最多记录接受到多少SYN。 net.ipv4.tcp_rmem tcp读缓存空间，三个值分别是最小、默认和最大。 net.ipv4.tcp_wmem tcp写缓存空间，三个值分别是最小、默认和最大。 net.core.somaxconn 最大连接数 修改/etc/security/limits.conf，提高文件句柄上限: soft nofile 65536 hard nofile 65536 socket池 nodejs的http模块内置socket池，默认 最多建立5个socket require('http').globalAgent.maxSockets = 40000 # 也可以设成Infinity，无限制 require('https').globalAgent.maxSockets = 40000 垃圾回收 nodejs会周期性地向V8发出垃圾回收请求，在并发大的时候经常这样会过多地占用CPU。可以通过启动node时加入 --nouse-idle-notification 选项，关闭这个动作。如: node --nouse-idle-notification app.js 多进程 nodejs虽然异步可以处理轻松地处理大量请求，但单进程单线程的模型在多核下还没有完全利用硬件资源。亲好nodejs原生的 cluster 可以很简单地让程序编程多进程。 cluster是prefork模型的，即前面一个master负责总的接受请求，然后均匀地把请求分发给worker，每个worker是一个独立的进程。 例如对于express的应用，在程序入口添加以下代码即可： var express = require ( 'express' ); ... if ( cluster . isMaster ) { // calculate number of proccesses to fork var num_cpus = require ( 'os' ). cpus (). length ; var num_processes = Math . max ( 1 , num_cpus - 1 ); debug ( 'Master starts with %d processes.' , num_processes ); for ( var i = 0 ; i < num_processes ; i ++ ) { cluster . fork (); } // Listen for dying processes cluster . on ( 'exit' , function ( worker , code , signal ) { debug ( 'A process(pid=%s) of master died (%s). Restarting...' , worker . process . pid , signal || code ); cluster . fork (); }); return ; } // worker var app = express (); ... 另外还有如 PM2 等外部工具可以让原来单进程的程序变成多进程 参考资料 http://www.oschina.net/translate/optimising-nginx-node-js-and-networking-for-heavy-workloads http://blog.caustik.com/2012/04/08/scaling-node-js-to-100k-concurrent-connections/ http://engineering.linkedin.com/nodejs/blazing-fast-nodejs-10-performance-tips-linkedin-mobile https://rtcamp.com/tutorials/linux/sysctl-conf/","tags":"programming","loc":"http://www.goorockey.com/blog/2014/07/20/high-concurrency-setting-for-nodejs/","title":"Node.js高并发配置"},{"text":"最近在做的系统准备加个消息队列，重构成\"master-queue-workers\"的结构. 感觉现在好多系统都是这个结构。这样master就专心接受用户的请求，把任务放进队列，让workers去处理。master就可以立刻回复用户，而不用等待处理完整个业务才回复。 主流的消息队列方案可以看 这里 。 我主要考虑的方案有rabbitMQ、redis、celery、mongodb。 rabbitMQ ： 之前在学erlang的时候就知道rabbitMQ，它在消息或任务队列里面是主流的方案，成熟稳定。同类的还有ZeroMQ等。 优点 ：成熟放心。 缺点 ：需要开发和运维都充分掌握，学习和维护成本较redis的高。 redis ：内部的列表支持对队列的操作，其中List的blpop是阻塞式的，满足消息队列的要求。 优点 ：使用和维护简单。自身的内存缓存特点也保证了速度。 缺点 ：因为不是原生设计成对消息队列的应用，有的队列操作还需要补充实现。这个有现成的库可以帮助解决，但可靠性、成熟度需要确认。 celery ：把rabbiMQ、redis、mongodb等作为后端，进一步的封装。最初是python的，现在也有nodejs版 优点 ：进一步的封装，可以方便把后端切换成不同的方案。python版相对比较成熟。 缺点 ：nodejs版还不够成熟，有点功能还不支持，比如底层现在指支持rabbitMQ，不支持redis mongodb : 其实也有人用mongodb的capped collection来做队列，鉴于它在node.js的应用中广泛被使用，它也是一种选择。 优点 ：如果本来应用就是用mongodb，那可以一并来用 缺点 ：当并发量大的时候，速度不理想 我最后选择了用redis。因为系统是用node.js写的，所有用到了node的 kue 库。","tags":"programming","loc":"http://www.goorockey.com/blog/2014/06/09/xiao-xi-dui-lie-fang-an-cu-lue-diao-yan/","title":"消息队列方案粗略调研"},{"text":"最近在搞nodejs，刚好有个点子，想实现一个对自己这个月在 Instapaper 的已读文章做回顾，通过邮件形式发到自己的邮箱，起到复习的作用。然后上周末就用了两个通宵把这搞出来了，代码放在 Github 上面。 总的情况 整个服务跑在 Appfog 上 用 SendGrid 服务发送邮件 nodejs实现, 用到了cheerio、request、cron、sugar、ejs、sendgrid等几个模块 抓文章 Instapaper提供有API，可以获取到已读文章，但它需要填表、人工审核，感觉不容易通过，索性就自己模拟登录，抓下来算了。F12看了一下，发现Instapaper通信协议极其简单，好抓得很。 nodejs抓网页，可以用cheerio，说比传统的JSDOM要快、要方便，用着确实方便。 Appfog Appfog是我挺喜欢的一个PaaS，它是基于Cloudary提供服务的，支持语言多，部署简单。 这次因为要定时发邮件，在Appfog上面要定时执行，需要部署一个 standalone app 。 nodejs这边要实现定时，要node-cron很方便就搞定了。 发邮件 Appfog上面提供SendGrid的插件。SendGrid在全球提供发邮件服务，为了防止垃圾邮件，其申请时的审核挺严格的。不过在Appfog上面想用SendGrid就简单得多，把插件启动了就好了，赞！ nodejs 用nodejs的异步回调机制开发，确实要转一下思维。有时候循环还不得不写成递归，很函数式语言。 中间遇到一个问题，就是Instapaper上的时间都是用moment.js或者timeago.js之类转成了XXX days ago、XXX months ago的语义式时间。因为我只想回顾最近这个月的文章，要做判断，所以要做逆过程，恢复成日期的。sugarjs这个模块很强大地解决了这个问题~","tags":"programming","loc":"http://www.goorockey.com/blog/2014/05/12/yong-nodejsshi-xian-instapaperhui-gu-you-jian-zi-dong-fa-song/","title":"用nodejs实现Instapaper回顾邮件自动发送"},{"text":"这几个月做的项目是把一个承载在MFC的软件从Windows移植到Mac，现在进入最后验收阶段了。当时网上调研了一下，决定用 wxWidgets 这个跨平台的开源库来帮助移植。总的来说，只要把原软件对Windows API的调用都改为对wxWidgets的调用，基本就完成了移植。但基于wxWidgets和MFC一些设计上的差异和原软件特殊的功能，还不是简单的全局替换就能了事的，甚至还得改wxWidgets的源码。 wxWidgets库在总的结构上跟MFC相似，比如消息响应、相关类的命名。它现在已经出到了3.0，总体还是比较成熟了，但还是好些不完善的地方，这个在看它源码的时候就会发现挺多TODO comment。不过它的官方论坛和stackoverflow上相关问题还是挺活跃的，在上面提问很快就能得到一些资深程序员的答复。有一次我误以为发现了它的一个bug（其实是我理解错了），在上面提问，回复的人不仅有文字的讲解，还附上了自己写的测试用例，让我真心赞叹对方好负责任啊。 现在总结一些项目移植过程中遇到的问题吧。 wxRect和CRect Windows的CRect要替换成wxWidgets的wxRect真不能简单的替换，因为两者内部设计不一样。 第一，两者对应接口的入参有不同，最经典的是两者的构造函数，CRect是传left,top,right,bottom，wxWidgets是传left,top,width,height，等于说所有构造CRect的地方都要把第三、第四个参数做减法。 第二，wxRect定义自己所表示的矩形，范围是[left, right - 1]和[top, bottom - 1]，意思就是右边界和下边界是不属于矩形一部分的，这个从其源码能看到。官方说法是不承认width或height为1的矩形，那应该视为线段。这在移植一些矩形操作时，会跟CRect的有些差异。 第三，也是我觉得最坑的，CRect内部直接保存left,top,right,bottom来定义矩形，而wxRect内部保存left,top,width,height来定义矩形，即wxWidgets要GetRight的时候，是返回left + width，SetRight的时候set的是width，其他的同理。这看着没什么问题。但如果我们先SetRight，再SetLeft，wxRect的行为就跟CRect的不一样了。 例如对一个(left,top,right,bottom)=(1,1,5,5)的CRect，对应的wxRect是(left,top,width,height)=(1,1,4,4)，我们对其依次执行SetRight(10)和SetLeft(3)，得到CRect是(left,top,right,bottom)=(3,1,10,5)，wxRect是(left,top,width,height)=(3,1,9,4)，换算过来wxRect是(left,top,right,bottom)=(3,1,12,5)，跟得到的CRect不同！原因就是SetLeft的时候，wxRect只改left，没改width，但等于right还是改了，其实是使整个矩形做了偏移；CRect的行为则是修改左边界，右边界不会动，其实是使整个矩形做压缩。真是坑啊！注意到这一点之后，原软件每个连续SetLeft、SetRight，SetTop、SetBottom的地方，都要注意执行的顺序。 鉴于wxRect和CRect以上的差异，其实移植的时候最好的做法是自己写一个封装了wxRect的MyRect类，把wxRect和CRect的差异在MyRect里面做转换。这其实是应用了Adaptor Pattern。 Mac下wxBitmap在剪切板wxClipboard取回时，Alpha信息丢失 wxWidgets在从剪切板wxClipboard取回图片数据wxBitmapDataObject时，会丢失了透明信息，即Alpha channel。具体来看就是原来用RGBA表示的有透明信息的图片，通过剪切板传递之后，RGBA的A都变成255了。 我通过查看wxWidgets的源码，发现确实是个bug，wxWidgets在Mac这边调用Cocoa接口从剪切板获取像素数据保存为图片时，没有关注Alpha channel。这个我通过修改它源码解决了。详见我提交到官方的这个 ticket 。 wxDC在Unix下不是线程安全的 wxDC是wxWidgets的绘制上下文，对应于Windows下的CDC。官方资料说了，wxDC在Unix平台下是非线程安全的。这里指的Unix平台具体是GTK(Linux)和OSX(Mac)。所以绘制的时候最好是下wxPaintEvent的响应函数里面做。在子线程做绘制不保证正确，即使是用wxWidgets的wxGuiEnter/wxGuiLeave加锁也是不行。 对话框资源的移植 在MFC中，对话框资源都保存在rc文件中。而对应到wxWidgets，每个对话框以xml格式保存成各自的xrc文件，跟rc有一定区别。MFC大部分控件在wxWidgets都能找到。对于对话框资源的移植，我们是用脚本批量完成的，中间一个坑是转换时候对话框和控件的大小在MFC的rc和wxWidgets的xrc不是1:1的，要乘一个比例，1.5左右。 ALL IN ALL 以上是暂时记得的问题。总的来说，wxWidgets是个强大的跨平台库，用着真心方便，常用的操作也都覆盖了，代码也整洁漂亮，社区也活跃，还是可以放心选用的。而且作为一个开源库，有什么问题都能自己定位自己修改解决，开源万岁～","tags":"programming","loc":"http://www.goorockey.com/blog/2014/04/21/yong-wxwidgetszuo-yi-zhi-de-zong-jie/","title":"用wxWidgets做移植的总结"},{"text":"好久没更新博客，水一文。 前阵子要给别人出试题，偶然发现 Web-Harvest 这个抓网页的工具，它主要应用xpath和xquery抓网页，内置还定义了一套功能挺多的语法，就出了一道用WH抓微博的题目。 本来想抓新浪微博的，但发现它的微博内容都是js生成的，折腾了一下，还是可以用WH的函数提取出内容，但腾讯微博相对还是简单多了。 题目其中一个内容是用WH抓几页邓紫棋的腾讯微博，排除包含她演唱会广告的和没有图片的微博。 其中遇到的坑： 因为是包含中文，写入到文件时要用gbk编码 在xpath已经用li[@id]获取微博节点，但节点传到xquery里面时竟然还要再一次用li[@id]获取一级 配置文件如下 [[ gist goorockey:9368146 ]]","tags":"programming","loc":"http://www.goorockey.com/blog/2014/03/05/yong-web-harvestzhua-teng-xun-wei-bo/","title":"用Web-Harvest抓腾讯微博"},{"text":"好久好久没有更新blog了，markdown怎么用都忘了。。写blog总结还是很有用的。今天写一下答应过某人写自己firefox的状况。 使用感受 主流的浏览器都用过，坚持用firefox的原因主要是因为 vimperator ，纯键盘地上网很cool很快捷，而且我用的时候会把地址栏、add-on bar等等都去掉，最大化可视范围。 虽然现在firefox在内存、响应速度上还是比不上chrome，但谁叫chrome的vim化插件不好用呢～ 另外用firefox写web的时候也比较方便，现在自带的\"Responsive Design View\"很方便地调试移动端的web体验。firefox每次升级都会有针对developer的new feature，足以看出它很重视开发者的功能。 插件 装插件折腾自己的firefox是必须的。当我看到有的人用firefox基本就是原装的，我都觉得他不适合用firefox，倒不如用另外国产标配好的浏览器让自己用得舒服一点。 vimperator 神器 Pentadactyl 神器，vimperator的分支 firebug 神器 greasemonkey 神器，firefox插件的扩展 NoScript 神器，控制网站的js adblock plus 去广告 Add to Search Bar 把一些常用的搜索加到搜索栏，如豆瓣。用它配合 Context Search X 使用 All-in-One Sidebar 侧边栏管理插件，下载等等 AutoPager 自动加载下一页 AutoProxy 科学上网 Context Search X 右击菜单选择指定搜索引擎来搜索鼠标选中的内容 DownThemAll 下载管理 feedly rss reader flashblock 默认禁止页面的flash，加快加载，页面体验也爽些 https finder 如果网页支持https，会自动用https instasaver instapaper的插件 lastpass 密码管理 Lazarus: From Recovery 恢复Form里面的输入 memroy fox 优化firefox的内存 quickdrag 鼠标拖拽 refcontrol 修改refer，破防盗链 RSS Handler for Feedly 在RSS处理项加入Feedly stumbleupon 发现好网站、消磨时间必备神器 tab mix plus 标签管理 UnMHT 平常是disabled的，有时候用来把网页保存为mht格式 View Source Chart 更有层次地看网站的源码 weibo_wc 重新定制新浪微博的样式，很整洁舒服 wiktionary and google translate 翻译 wiznote web clipper 为知插件 greasemonkey插件 新浪微博V5 还我漂漂版 取代weibo_wc HTTP-to-HTTPS redirector 本来是用插件版的 http everywhere 和 https finder 的，但可惜前者不能在firefox sync同步，后者发现有时候转不了 其他 主页设成空白页，这样每次打开都是自己主动获取信息，而不会在\"自己以为有用的网站\"上浪费时间和精力 autoproxy+ greatagent ，配合https，科学上网 更新 2014.07.03 firefox29更新界面之后，地址栏默认就不能去掉，虽然可以用 classic theme restorer 来回复以前的界面。现在没用vimperator，改用它的分支 Pentadactyl 。它更新比vimperator要频繁，它默认就能把地址栏去掉。 vimperator的一个成员在 网上 回答vimperator和Pentadactyl的区别: vimperator致力于让用户更简单地用vim的操作使用firefox Pentadactyl则更倾向于高级用户，有更强大的定制性","tags":"others","loc":"http://www.goorockey.com/blog/2013/09/08/wo-de-firefox/","title":"我的firefox"},{"text":"最近在刷题，总想把题目保存下来，这样没网的时候也可以做题，放手机里也可以随时做了。所以就想着把题目抓下来保存为比较通用的pdf了。 一开始想的是先做类似整站下载，把文字和图片都抓下来，然后再做html转pdf。自己写工具抓下来的话，要抓图片、修改网页里面图片的链接，昨天调研了一下，没找到用python有什么方便的办法，就放弃这条路了。 今天突然找到，网上还是有很多直接网页保存为pdf的工具、网站的。最方便、强大的要数 pdfmyurl 了。 pdfmyurl 可以通过http://pdfmyurl.com?url=\\<siteurl> ,来把指定链接的网页保存为pdf，而且是直接返回的，即用wget http://pdfmyurl.com?url=\\<siteurl>就可以直接得到所需的pdf，不用再按什么按钮之类的了。 在官网上可以发现，pdfmyurl可以算是个api服务，可以通过传很多get参数来得到需要的pdf结果。比较常用的有： --filename 输出的pdf文件名 --page-size 页面大小，默认是A4 --proxy 通过制定的代理访问该页面，--username --password还指定用户和密码 -b 使得到的pdf有目录、书签、页眉等书的样式，不过目录不咋地 pdfmyurl已经很强大了，但每次只能完成一个网面的pdf，所以还得想办法做pdf的合并。 pdftk pdftk 也是一个pdf方面的神奇，可以完成pdf合并、合并多个pdf指定页、分割、加水印等，而且是跨windows、linux、mac多个平台的。不过我也只用来合并pdf: $ pdftk 1.pdf 2.pdf cat output 12.pdf 但弄出来的pdf是没有目录的。 所以更好的办法其实是用更强大的latex。不过latex还有待系统地研究，现在的再写个bash就已经满足我90%的要求了～ 更新： 今天还是发现了一个用python抓oj的，有空参考一下，自己实现一个。 今天还发现，pdfmyurl似乎对单个ip一定时间内的请求做了限制，超过限制后，请求都会返回一个错误信息的pdf。我就借cjb的tor解决了这个问题（又用tor干了邪恶的事了）。","tags":"others","loc":"http://www.goorockey.com/blog/2012/10/29/zhua-wang-ye-bao-cun-wei-pdf/","title":"抓网页保存为pdf"},{"text":"由于某种原因，今天玩了一下 Hadoop 。正确来说，我是玩 HOP ，一个Hadoop的修改版本。 The Hadoop Online Prototype (HOP) is a modified version of Hadoop MapReduce that allows data to be pipelined between tasks and between jobs. This can enable better cluster utilization and increased parallelism, and allows new functionality: online aggregation (approximate answers as a job runs), and stream processing (MapReduce jobs that run continuously, processing new data as it arrives). 就是多了pipeline（流水线）的Hadoop。分布式流水线可以有效加快各jobs在各节点的同步运算。 准备 我是在linux上弄的，windows下用cygwin也行。 下载HOP压缩包后，看里面的docs就够了，同时src/example还有一些例子。 确保ssh,sshd,rsync,jdk都有了。同时要保证ssh localhost不要输入密码的认证步骤。具体docs/quickstart也有说，可以这样： $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys 然后是设置jdk的目录，修改conf/hadoop-env.sh中JAVA_HOME。一般为/usr/lib/jvm/下的某个java目录，我就直接写成/usr/lib/jvm/default-java了。 这时候执行bin/hadoop就会出现帮助信息了。 跑例程 Hadoop的文件系统叫 HDFS （Hadoop distribution filesystem)，是一个分布式文件系统。每份数据都会在多个节点有备份，以容错、修复。所有数据都要先放进HDFS才能Hadoop处理。 Hadoop的分布式体系中，有一个NameNode，是master的角色，负责主控各节点，有多个DataNode，是slave，负责真正存储数据。这些可以在conf/master和conf/slave设置。 同时还有一个JobTracker，负责调度jobs，默认就是NameNode这个主机一起充当NameNode，这个在conf/hadoop-site.xml设置。另外所有DataNode都是TaskTracker，负责执行jobs。具体更多对conf/hadoop-site.xml的配置参看docs/cluster_setup.html 执行bin/hadoop namenode -format，会创造一个namenode。文件都已某种格式放在/tmp/hadoop-\"hostname\"那里。 执行bin/start-all.sh会启动hadoop，默认通过http://localhost:50070/可以访问NameNode，http://localhost:50030/可以访问JobTracker。 现在执行一个例子: $ mkdir input $ cp conf/*.xml input/ $ bin/hadoop fs -put intput input # 把当前文件系统input目录复制为HDFS的input $ bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+' # 执行所有example.jar，后面的是参数 # 一段时间后，执行完毕 # $ bin/hadoop fs -get output output # 把HDFS中的output目录复制为当前文件系统的ouput $ cat output/* # 打印结果 # 或者直接对HDFS操作 # $ bin/hadoop fs -ls output $ bin/hadoop fs -cat output/* WordCount例子 WordCount 是hadoop中的另一个例子 Hadoop是通过 MapReduce 机制来处理大数据的。Map阶段分割输入的数据，并整合成\\<key,value>的对应关系。每对\\<key,value>对送到Combiner做每个key的整合，当整合出一定数量的\\<key,value>后，\\<key,value>会送到Reducer做处理输出最终的\\<key,value>。 (input) <k1, v1> -> map -> <k2, v2> -> combine -> <k2, v2> -> reduce -> <k3, v3> (output) 按照 WordCount 中的代码编辑WordCount.java，然后编译打包生成wordcount.jar: $ mkdir wordcount_classes $ javac -classpath hadoop-hop-0.2-core.jar -d wordcount_classes WordCount.java $ jar -cvf wordcount.jar -C wordcount_classes/ . 然后自行构造一些要统计的文件，放在input目录下。这时候注意，在执行了上一次例子后，如果想把输入文件还是放在HDFS的input下，要先清空原来的文件: $ bin/hadoop fs -rmr input/ $ bin/hadoop fs -rmr output/ $ bin/hadoop fs -put input input # 把输入文件目录input重新放到HDFS中 $ bin/hadoop jar wordcount.jar org.myorg.WordCount input output # 执行wordcount.jar # 执行一段时间后完毕 # $ bin/hadoop fs -cat output/* # 打印结果 结语 尝试了一下Hadoop，还有更多有待研究","tags":"hadoop","loc":"http://www.goorockey.com/blog/2012/10/21/wan-yi-xia-hadoop/","title":"玩一下hadoop"},{"text":"今天做 exploit exercise 的nebula level01 ，长见识了，记录一下。 题目 题目提供了/home/flag01/下flag01的源码： #include <stdlib.h> #include <unistd.h> #include <string.h> #include <sys/types.h> #include <stdio.h> int main ( int argc , char ** argv , char ** envp ) { gid_t gid ; uid_t uid ; gid = getegid (); uid = geteuid (); setresgid ( gid , gid , gid ); setresuid ( uid , uid , uid ); system ( \"/usr/bin/env echo and now what?\" ); } flag01的权限： -rwsr-x--- 1 flag01 level01 7322 2011-11-20 21:22 flag01 flag01的uid是用户flag01,gid是level01,suid位被使能了 解决方法 网上都有： $ export PATH = /tmp: $PATH # 把/tmp加到环境变量PATH的最前头 $ cat \"/bin/bash\" >> /tmp/echo # 在/tmp创建一个echo文件，里面是执行bash $ chmod +x /tmp/echo # 把/tmp/echo设为执行文件 $ /home/flag01/flag01 # 执行/home/flag01下的flag01 # 顺利以用户flag01起bash $ getflag # 通关 原理 主要原理网上的解法都说得很明白，就是通过env使得执行的echo是我们创建的假echo，成功以用户flag01的权限起bash 我想记录的主要是前面关于uid,gid的操作。 为什么system之前会有getegid,setresgid这些操作呢？没有会怎样？这还会成功吗？ 答案是不行的！在 stackoverflow 找到解答: Note that the setting of real user ID, effective user ID and saved set-user-ID by a call to setresuid() before the call to system() in the vulnerable code posted in the question allows one to exploit the vulnerability even when only effective user ID is set to a privileged user ID and real user ID remains unprivileged (as is for example the case when relying on set-user-ID bit on a file as above). Without the call to setresuid() the shell run by system() would reset the effective user ID back to the real user ID making the exploit ineffective. However, in the case when the vulnerable code is run with real user ID of a privileged user, system() call alone is enough. man page of sh: If the shell is started with the effective user (group) id not equal to the real user (group) id, and the -p option is not supplied, no startup files are read, shell functions are not inherited from the environment, the SHELLOPTS variable, if it appears in the environment, is ignored, and the effective user id is set to the real user id. If the -p option is supplied at invocation, the startup behavior is the same, but the effective user id is not reset. real user ID, effective user ID，saved set-user-ID, set-user-ID bit 首先明确什么是real user ID, effective user ID，saved set-user-ID, set-user-ID bit real user ID 就是起进程的用户ID。 effective user ID是进程的有效用户ID，决定这个进程对文件系统操作的权限。如果它是root，那这个进程的操作就是以root的权限了。 set-user-id bit是程序的一个特征位，默认不使能，可以通过chmod +s 设置。当set-user-id被使能时，此程序叫SUID程序，程序启动时进程的effective user ID就是这个程序的uid；当set-user-id没被使能，则effective user ID是执行者real user ID。 saved set-user-ID保存着进程启动时effective user ID的值。 因为进程内可以通过setuid等来设置effective user ID，也就改变了进程对文件系统操作的权限。但这不是可以随便设为任意的id的。 如果进程有管理员权限，则setuid可以把effective user ID设为任意id. 如果进程没有管理员权限，则setuid只能把effective user ID设为real user ID或者saved set-user-id。 这就知道saved set-user-ID有什么用了。它就是当程序是SUID程序时，effective user ID可以被设为real user ID和程序启动时的effective user ID，saved set-user-ID就是用来保存这个程序启动时effective user ID的值的，使得setuid可以把effective user ID可以从real user ID设回来。 bash 然后就是起bash时，如果effective user ID跟real user ID不同，且real user ID不是管理员权限用户，则会把effective user ID设回real user ID。 而我们这样如果没有setresgid,setresuid的话，real user ID是level01, effective user ID是flag01, 起bash时，effective user ID会被设回real user ID，那还只是以level01起bash，而不是flag01起bash了。 system()的安全问题 在这里也可以看到system()是有安全问题的，因为system()里面是fork完就直接调用execl，使得继承了父进程的effective user ID的子进程执行新的程序。 APUE也说了: If it is running with special permissions--eithere set-user-ID or set-group-ID--and wants to spawn another process, a process should use fork() and exec() directly, being certain to change back to normal permissions after the fork(), before calling exec(). The system() function should never be used from a set-user-ID or a set-groupd-ID program. 意思在SUID程序中，不应该用system()，而是自己写fork()和exec()来实现，并在fork和exec中间，自己处理好id权限问题。 结语 之前看APUE，用户id这里看得一头雾水，通过这个exercise，总算有点感觉了。","tags":"linux","loc":"http://www.goorockey.com/blog/2012/10/10/guan-yu-exploit-exercise-nebula-level01/","title":"关于exploit exercise nebula level01"},{"text":"项目组有每天值日搞卫生和发工作日报的规定，由于不提醒容易忘记，则想到通过内部邮件定时提醒，练练手。 整个\"任务\"可以分为发邮件+定时两部分。 发邮件 由于服务器是windows系统，google得知，windows下有 blat 这发邮件的大杀器，所以刚开始是想用blat+批处理做的。 执行 blat -h 或者看官网上的帮助，使用blat发邮件还是很简单的（所以官网特别提醒不要用blat来发SPAM。。) blat <邮件正文文件> -from <发送地址> -to <接受地址> -subject <邮件标题> -server <smtp服务器地址> -username <登录服务器用户名> -password <密码> blat - -body <邮件正文> -from <发送地址> -to <接受地址> -subject <邮件标题> -server <smtp服务器地址> -username <登录服务器用户名> -password <密码> blat还可以通过-install把参数保存到注册表。blat确实是自动发邮件的大杀器！ P.S 在linux实现自动发邮件，可以用msmtp,sendmail等～ 这本来是很简单的，但因为任务要根据星期几发送邮件给指定的人，而且我们是12个人分成两周，所以想到用一个二维数组存放成员来实现，这也没什么问题。 问题在于在计算要提醒的人时，要根据今天离开始值日的天数，来从数组获取成员，而这求天数在windows用批处理可不好搞，因为要考虑每月不同天数和闰年啊。 当然也不是不能完成，网上也有方法: http://bbs.bathome.net/thread-11128-1-1.html http://bbs.bathome.net/viewthread.php?tid=5659&highlight=%2Bbatman http://bbs.bathome.net/viewthread.php?tid=5682&highlight=%2Bbatman 嫌麻烦，我还是决定找有现成库的方法来做，所以就想到用有各种库的python实现了。 python有 smtplib 库实现smtp发邮件，核心代码也很简单： import smtplib # some code ... smtp = smtplib . SMTP () smtp . connect ( server ) smtp . login ( username , password ) smtp . sendmail ( sender , receiver , msg ) smtp . quit () 而用python计算相差的天数更是简单不过： import datetime # some code ... days = ( datetime . datetime . now () - datetime . datetime ( 2012 , 9 , 30 )) . days 定时 定时在windows可以用计划任务实现 P.S 在linux可以用cron实现 整个代码 #coding=utf-8 import smtplib import datetime import sys from email.mime.text import MIMEText from email.header import Header member = (( 'member1' , 'member2' , 'member3' , 'member4' , 'member5' , 'member6' ), ( 'member7' , 'member8' , 'member9' , 'member10' , 'member11' , 'member12' )) suffix = '@abc.com' def send_mail ( receiver , content_filename , sender = 'admin@abc.com' , server = '192.168.1.1' , username = 'admin@abc.com' , password = 'admin' ): subject = '' content = '' # 从文件读取邮件正文 try : content_file = open ( content_filename , 'r' ) try : subject = content_file . readline () content = content_file . read () # 转为utf-8 subject = subject . decode ( 'gbk' , 'ignore' ) . encode ( 'utf-8' ) content = content . decode ( 'gbk' , 'ignore' ) . encode ( 'utf-8' ) finally : content_file . close () except IOError , e : sys . stderr . write ( \"cannot open file \" + content_filename ) return content = content + \" \\n\\n 系统生成，请勿回复 :)\" #print content # 构造邮件 msg = MIMEText ( content , 'plain' , 'utf-8' ) msg [ 'Subject' ] = Header ( subject , 'utf-8' ) msg [ 'From' ] = sender msg [ 'To' ] = receiver if ( len ( msg ) > 0 ): try : # stmp模块发送邮件 smtp = smtplib . SMTP () smtp . connect ( server ) smtp . login ( username , password ) smtp . sendmail ( sender , receiver , msg . as_string ()) smtp . quit () print \"Success\" return True except Exception , e : print str ( e ) return False def get_on_duty (): receiver = '' days = ( datetime . datetime . now () - datetime . datetime ( 2012 , 10 , 8 )) . days if days > 0 : days = days + 1 # 提前一天提醒 week = ( days / 7 ) % 2 date = ( days % 7 ) # 周六发周一的值日 if date == 6 : date = 0 if week < len ( member ) and date < len ( member [ week ]) and len ( member [ week ][ date ]) > 1 : receiver = member [ week ][ date ] + suffix return receiver if __name__ == '__main__' : if len ( sys . argv ) > 1 : job = sys . argv [ 1 ] # 值日 if job == 'duty' : receiver = get_on_duty () print receiver content_filename = 'duty.txt' if datetime . datetime . now () . weekday () == 5 : content_filename = 'duty_Sat.txt' if len ( receiver ) > len ( suffix ): send_mail ( receiver = receiver , content_filename = content_filename ) # 每天日报提醒 elif job == 'daily' : send_mail ( receiver = 'partner' , content_filename = 'daily_alert.txt' )","tags":"python","loc":"http://www.goorockey.com/blog/2012/09/30/pythonfa-you-jian-jiao-ben/","title":"python发邮件脚本"},{"text":"最近学scheme，总结一下pair和list的区别，主要是两点： 1.list一定是pair，但只有以null（空list）结尾的pair才是list 对于(define list1 (list a b c)),list1表现为(a b c),其实也可以写成(a . (b . ()))。 可以看到list其实就是pair,而且是以null结尾的pair。 对于像(a.(b.(c.d)))这样的连续pair，因为没有以空list结尾，所以不是list 所以有： > (define x '(1 2)) > x (1 2) > (list? x) #t > (cons? x) #t > (cddr x) ; 以null结尾 () > (define y (cons 1 2)) > (list? y) #f > (cons? y) #f > (set-cdr! y '()) ; 把y的cdr设为null，使y变成list > y (1) > (list? y) ; 变成了list #t > (cons? y) #t 2.pair的显示规则 引用 这里 的解释： In general, the rule for printing a pair is as follows: use the dot notation always, but if the dot is immediately followed by an open parenthesis, then remove the dot, the open parenthesis, and the matching close parenthesis. Thus, (0 . (1 . 2)) becomes (0 1 . 2), and (1 . (2 . (3 . ()))) becomes (1 2 3). 大意就是，如果pair的\"点\"紧接着小括号，则这个点和小括号都可以去掉。 所以(a.(b.c))等价于(a b.c), (a.(b.(c.())))等价于(a b c)。","tags":"lisp","loc":"http://www.goorockey.com/blog/2012/09/25/schemeli-mian-de-pairhe-list/","title":"Scheme里面的pair和list"},{"text":"[TOC] 想尝试 Octopress 很久了。 Octopress 自称为A blogging framework for hackers 玩 Octopress 主要会涉及到以下技术: git ruby markdown 这些技术对我来说还是很陌生，也好借此机会熟悉熟悉～ 总的来说，[Octopress］想对于Wordpress的优势有: 静态页面，速度快 分布式存储，保证数据的安全。而且即使不能上网，也能本地写博客和预览 支持用markdown（当然wordpress也有markdown的插件, 但Octopress在命令行写博客更cool) 仿照着，写了个友情链接侧栏的插件, 当然直接在source/_include/asides/ 写静态页面也可以，纯练手: [[ gist goorockey:3689183 ]]","tags":"blog","loc":"http://www.goorockey.com/blog/2012/09/09/cong-wordpresszhuan-dao-octopress/","title":"从Wordpress转到Octopress"},{"text":"继续用VMWare来组网，这次要测试我想试很久的DNS隧道，之前碍于没有找到有独立ip的方法（当然是要免费的~~），现在用VMWare就可以了。 DNS隧道是什么就不解释了。google一下DNS隧道能搜到风河、云风两个大牛相关的blog。这次我用iodine来实现DNS隧道。 场景 现在情况是，用户只能跟外界有DNS通路，想借此进行平常的http、ftp等通信。 据说平常的CMCC等开放热点，虽然http等要账号和密码，但DNS是通的，然后你懂的了。 简单的拓扑图如下： 整个回路就是： 用户把要想跟外网进行通信的数据包用DNS协议封装 得到的DNS包发送给DNS服务器，要求做DNS解析 DNS服务器根据域名，解析出DNS代理的ip，并把数据包发给它 DNS代理把数据包解封，并转发给外网的目标地址 外网回复的数据包原路返回，这样就完成通讯了。 VMWare环境模拟 这次我用了三台机子，系统还是CentOS 6.0： 主机名 角色 网卡ip HostA 用户 192.168.149.128 (Host-only) HostB DNS代理 192.168.126.130 (NAT) HostC DNS服务器 192.168.149.130 (Host-only)、192.168.126.233 (NAT) 要模拟的初始状态就是： HostA（用户）可以跟HostC做DNS解析，但不能访问外网 。 （所以虚拟网卡用Host-only模式） HostB（DNS代理）可以跟外网通信。 （用NAT和Bridged都可以，这次我选用NAT） HostC（DNS服务器）可以跟HostA进行DNS解析，且能跟HostB通信。 （所以用两张网卡，为了分别跟HostA和HostB通信） HostA的iptables不允许HostA和HostB之间互访 DNS服务器配置 刚开始看教程好像很繁琐，感觉conf文件好多啊，而且配置项也多~~ 静下心来看，其实要实现最基本的的DNS解析很简单，主要就是修改两个文件。 1.安装 需要在HostC执行以下命令，安装DNS服务器所需的bind和caching-nameserver： $ yum install –y bind bind -utils bind -chroot caching-nameserver 2.修改named的conf文件（/etc/named.conf） 添加域名goorockey.go域名的配置： zone \"goorockey.go\" IN { type master; file \"goorockey.go.zone\"; allow-update {none; }; } 大概解释： zone \" goorockey.go\"： 指示要添加goorockey.go这个域名的正向解析。正向解析就是指域名到ip的解析，反向解析是指ip到域名的解析。例如想通过查询DNS服务器，知道192.168.0.1判定了多少域名，则在DNS服务器上配置zone \"1.0.168.192.in-addr-arpa\"的项。 type master：对于goorockey.go这个域名，当前DNS服务器是它的主DNS服务器。type可以还可以使hint和slave。只有zone \".\"可以配置type hint。type slave是指对于这个域名，当前DNS服务器是辅助DNS服务器，即它的DNS记录是从主服务器拷贝过来的，目的是为了达到DNS解析的分布式、负载均衡。 file \"goorockey.go.zone\"：这个域名的DNS记录文件在goorockey.go.zone，文件所在目录在/etc/named.conf的options项中的directory来定义。默认是/var/named allow-update：定义时候允许更新 要注意的是，/etc/named.conf中的options项是所有域名的全局配置。默认时，有： allow-query { localhost; }; 意思是只允许本机做DNS查询，当然要把它注释掉。 listen-port 53 { 127.0.0.1; }; 意思是服务端口为53，但监听的ip是127.0.0.1，这样就不能让别的机子访问DNS解析服务了。所以可以把这句话注释掉，或者把ip改为0.0.0.0或指定ip。 3.编辑goorockey.go的DNS记录文件 根据我们在/etc/named.conf的配置，文件是/var/named/goorockey.go.zone。 创建此文件，并编辑内容为： @ IN SOA localhost. root.localhost. (20120315 3600 1800 36000 3600) IN NS localhost. goorockey.go IN A 192.168.126.130 大概解释： 第一行是一条SOA记录。@指代当前域名，就是/etc/named中的goorockey.go。SOA记录是域名有效性的相关属性。localhost.是主服务器的地址。root.localhost.是邮箱。主要DNS记录文件的地址都用FQDN，每个地址最后的句号\".\"表示结束。如果没有句号\".\"，会自动追加域名，例如没有句号的localhost会解释成\"localhost.goorockey.go\"。后面就是具体属性项。 第二行开始是两个空格，第一个空格表示继续上一条的内容，这里指\"@\"，第二个空格就是分割@和IN的。这一行表示域名goorockey.go的域名服务器是本机。 第三行是一条A记录，A for address。意思就是域名goorockey.go会解析成ip 192.168.126.130。可以看出，搞这么久，就是为了找到这句话。所以说A记录是DNS服务器的核心，就是它标明DNS解析的。 DNS记录类型还会有： PTR用在反向解析 MX用在邮件服务器 TXT就是纯文本，对DNS服务器做标注 4.运行DNS服务 在HostC执行： $ service named start 或者 $ /etc/init.d/named start ,这就可以运行DNS服务了。 对HostC的/etc/resolv.conf添加 nameserver 127.0.0.1 则在HostC用nslookup能成功返回DNS信息： 但还要配置iptables，使其他机子可以访问DNS服务的端口。 对于默认的53端口，在HostC运行： $ iptables –I INPUT -p tcp --dport 53 -j ACCEPT $ iptables –I INPUT -p udp --dport 53 -j ACCEPT 要解释一下的是，DNS包有可能以tcp或者udp方式传输。一般首选是udp方式。但因为udp包长度只能是512字节，也不能分包，所以如果当DNS包长度大于512时，就会选择tcp方式。所以这里要对tcp和udp都设置ACCEPT。 在HostA和HostB的/etc/resolv.conf添加HostA的ip后，就能正确解析goorockey.go了。 iodine iodine是外国人写的开源DNS隧道工具，有linux版、windows版和Mac版的。教程看它的ReadMe或者HowToSetup都比较清楚。 下载并安装对应自己版本的iodine后就能使用了。 在DNS隧道的服务器端(HostB)，先执行： $ iodined -f 10.0.0.1 goorockey.go 输入密码后，服务端就运行了。注意服务端运行的是iodined，有\"d\"。 在客户端（HostA)，执行： $ iodine -f -c 192.168.126.130 goorockey.go 其中192.168.126.130是服务端（HostB）的ip。 然后还要配置一下，HostA，HostB，HostC的iptables，使它们的DNS包可以通过就可以了。 这时候，HostA的虚拟网卡ip是10.0.0.2，HostB的虚拟网卡ip是10.0.0.1。两台机子已经建立了VPN。 本来两台不能互访的机子就可以访问了。 例如在HostA就可以ssh HostB了 ： $ ssh 10.0.0.1 然后就可以用ssh隧道过去来做代理了~~ 小结 那时候看到DNS隧道，真是非常的兴奋，感觉太爽、太妙了。其实协议都可以这样做隧道，只是那时候没有意识到而已。 之后还继续想实验一下ICMP隧道，看一下iodine的代码。O(∩_∩)O哈哈~ 参考资料： 【风河的博文】 http://www.nsbeta.info/archives/96 【云风的博文】 http://blog.codingnow.com/2011/06/dns_tunnel.html 【iodine】 http://code.kryo.se/iodine/","tags":"network","loc":"http://www.goorockey.com/blog/2012/03/15/yong-vmwarezu-wang-shi-yan-dnssui-dao/","title":"用VMWare组网，实验DNS隧道"},{"text":"本着\"干中学\"的精神，看完资料，还是用VMWare来练习一下使用NAT，好加深认识。 实验涉及：NAT，iptables， 实验目标 这次我要用iptables实现NAT功能（SNAT和DNAT）。 先上拓扑图（可能有点不规范）： 如图分别有4台机子：A、B在内网，但在不同的网段中，C做网关，控制网段间的访问。D在外网。 要达到： A、B能通信（内网不同网段的互访） A、B能通过C与外网通信 D能通过C访问到A、B的服务 环境 用VMWare虚拟出这4台机子，VMWare的版本为8.0 每台机子都跑CentOS 6.0 VMWare环境配置 安装4个虚拟机，都装上CentOS，主机名分别定为hostA、hostB、hostC、hostD，对应A、B、C、D。 VMWare新建几张网卡（菜单栏【edit】-【Virtual Network Editor】），要求一张为Bridged（NAT应该也行），两张为Host-only。 设置A、B网卡分别为VMnet1和VMnet2，这是为了使它们原始都不能互访。 外网的D网卡设为VMnet0 C则有三张网卡VMnet0、VMnet1、VMnet2，这样C原始都能访问到A、B、D。 然后进入每个虚拟机，为了方便，我都设置为静态ip（网段跟上图对应）： A：192.168.149.128 B：192.168.214.128 C：192.168.4.233（eth0），192.168.149.130（eth1），192.168.214.130（eth2） D：192.168.4.234 CentOS里面配置网卡方法就是修改/etc/sysconfig/network-scripts/ifcfg-eth*，没有则自己创建一个。 关键项就是ONBOOT，IPADDR，NETMASK，GATEWAY，DNS1，DNS2，PEERDNS 要注意的是，有PEERDNS项，当它值为yes，则会把DNS1和DNS2覆盖地写入/etc/resolv.conf。 这对于多网卡的C，如果ifcfg-eth0、ifcfg-eth1、ifcfg-eth2都设了PEERDNS，由于开机是按名字的顺序执行，则会把ifcfg-eth2的DNS写入/etc/resolv.conf，前两个文件的DNS会无效了的。所以我只在ifcfg-eth0配置PEERDNS=\"yes\"。 好，初步网络环境配置完成。 现在情况是： ABD都不能互访，因为在不同的网段 C则都能跟它们三个互访 配置网关C的iptables，实现NAT 到关键也是好玩的地方了。 接下来配置网关C的iptables，实现不同网络间地址的转换（NAT）。 iptables内容比较多，详细可以参考： http://www.frozentux.net/iptables-tutorial/cn/iptables-tutorial-cn-1.1.19.html 1.A、B通过C实现通信 这个比较简单，没用到iptables，把A的网关设为C的对应网卡的ip（192.168.149.130），B的网关设为C对应网卡的ip（192.168.214.130）。 然后打开C的ip转发，在C中执行： $ echo 1 > /proc/sys/net/ipv4/ip_forward 这就把C作为了A、B的网关。A、B间通信的数据包会发到C，靠C的网卡间转发来完成通信。AB就可以相互ping通了。 2.A、B通过C与外网通信（SNAT） 现在A、B都不能跟D通信，因为现在A、B发到D的数据包源地址（192.168.149.128,192.168.214.128），D是无法知道的（D在C的同一个网络，网关设为相同的ip）。则包可以发到D，但D回复不了，因为它的网关不知道A、B。 现在就通过SNAT把A、B发送的包在经过C时，把源地址改为C的外网ip（192.168.4.233），这个D是知道的，也就可以顺利回复了。 具体在C中执行： $ iptables –t nat –A POSTROUTING –o eth0 –j SNAT --to-source 192.168.4.233 这样A、B就能ping通了。 SNAT可以看看我的博文。 嘻嘻…… 3.D通过C访问A、B的服务（DNAT） 现在A、B可以跟D通信，但D不能主动访问A、B。还是因为D只知道C，不知道A、B。 假如现在A开了19991口的sshd： 在A的/etc/ssh/sshd_config中添加： ListenAddress 0.0.0.0:19991 重启sshd $ service sshd restart 在A中让iptables允许对19991口的访问 $ iptables –I INPUT -p tcp --dport 19991 -j ACCEPT 现在D想ssh到A的19991，则可以在C中执行以下命令，实现DNAT： $ iptables -t nat -A PREROUTING -p tcp --dport 19991 -j DNAT --to-destination 192.168.149.128 现在D可以通过ssh到C的19991口来ssh到A了。 小结 整个实验搞完，对iptables，NAT的原理还是深刻了不少。 然后，就是VMWare是个好东西。","tags":"network","loc":"http://www.goorockey.com/blog/2012/03/13/vmwarezu-wang-shi-yan-nat/","title":"VMWare组网实验(NAT)"},{"text":"最近要恶补一下计算机网络的基础知识，今天先总结一下NAT。 NAT的背景 随着Internet的普及，网络中的ip资源是越来越紧张。而NAT就是为了解决这个问题的方案。 NAT是Network Address Translation,网络地址转换，会在网关中实现局域网内部ip和外网ip之间转换。 如上图，局域网内部网段是192.168.1.X，这些ip只在这个局域网内有意义，外网无法根据这些ip定位计算机。 而NAT就是做内网和外网这样两个网络间的ip转换。 NAT的类型 按照通信发起方的不同，NAT可以分为： SNAT，即Source NAT DNAT，即Destination NAT 1.SNAT SNAT是对数据包源ip的转换，主要用于内网机子发起连接到外网的情况。 【考虑以下场景】： 内网ip为192.168.1.2的机子向外网的8.8.8.8发包。如果数据包的源ip直接就是192.168.1.2，数据包虽然可以成功到达8.8.8.8，但是它无法根据192.168.1.2的源ip回复数据包，因为在外网中没有192.168.1.2，则造成通信失败。 而SNAT就是当内网发起连接到外网时，具有NAT功能的机子，例如网关，在数据包要出外网之前，把包的源ip改为这个局域网的外网ip，如1.1.1.1，同时会有映射表记录转换。 由于1.1.1.1是外网中有意义的ip，1.1.1.1和8.8.8.8可以成功的完成数据包的发送和接受。这时8.8.8.8是把1.1.1.1作为目标ip回复数据包，网关收到数据包后，会查表把包的目标ip映射回内网机子ip 192.168.1.2。 可以看出来，整个过程对内网机子是透明的，即发送和接受数据包的ip都对应，仿佛没有做过转换。 2.DNAT DNAT是对数据包目标ip的转换，主要用于外网向内网发起连接的情况。 【考虑一下场景】： 在内网中有很多机子，其中有一台ip为192.168.1.2的机子是对外网提供服务的web服务器，现在外网的8.8.8.8要访问它。但对于8.8.8.8来说，web服务器所在ip会是192.168.1.2所在内网的外网ip，如1.1.1.1。 可想而知，当8.8.8.8向1.1.1.1发送数据包，网关会做DNAT，把包的目标ip从1.1.1.1改为192.168.1.2，同时会把转换记录到一个表中。然后192.168.1.2回复数据包，包的源ip是192.168.1.2，目标ip会是8.8.8.8。网关接受到包后，则查表，把源ip修改回1.1.1.1。 NAT的转换方式 NAT有四种转换方式： 静态NAT (Static NAT) 动态NAT (Dynamic NAT) 过载 (Overload NAT) 重叠 (Overlap NAT) 1.Static NAT 局域网有多个外网ip，数量等于或多于内网ip数。 则做NAT转换时，每个内网ip对应一个外网ip。 网关的表中记录着这样一对一的关系。 2.Dynamic NAT 局域网有多个外网ip，但数量少于内网ip数。 则做转换时，每个内网ip从当前未被映射的外网ip选取一个来做转换。 网关的表也会记录这种转换，且会根据情况不断更新。 3.Overload NAT 如果局域网只有一个外网ip，每个内网ip都映射到这个外网ip，但端口口会不同。 网关的表中会记录这种端口的映射。 4.Overlap NAT 当内网的ip在外网中已经注册且已被其他机子使用时，网关要在选择一个外网中已注册但未被使用的ip做转换。 网关的表中记录这种转化。 小结 其实所谓的内网和外网都是相对而言，只要是两个网络间的通信，都可以或需要用网关或路由做NAT。 【参考资料】： http://article.yeeyan.org/view/185403/150856 http://zh.wikipedia.org/wiki/网络地址转换","tags":"network","loc":"http://www.goorockey.com/blog/2012/03/11/natxue-xi-zong-jie/","title":"NAT学习总结"},{"text":"背景 之前就试过几次想把linux作为宿主来玩，但都因为舍弃不了一些windows下的软件而放弃了，例如wiz，qq等都是我常用的软件。试过wine，但总是有点错误，不完美。 最近也在微博上收集意见，发现用linux做宿主系统的人还是蛮多的。其实仔细想想，归根结底还是自己linux的操作还不熟练。 还好最近一段时间自己多了在linux的工作，这几天又下定决心一次装了linux做宿主来玩了。然后就想写个blog记录一下。 系统 这次选的linux的linux mint(64bit)，一个基于ubuntu的linux发行版。 官方说其目标是成为有windows那样市场占有率的linux发行版。 我不大喜欢ubuntu现在的natty，所以就在虚拟机试用了一下linux mint，感觉比ubuntu方便。 工具 浏览器 ：firefox。一直用firefox，插件强大。 知识管理 ：evernote。本地用nevernote，它是evernote的linux版；网页摘取用firefox的evernote clip。 X windows : awesome。一种平铺窗口管理器。本来想用musca，但我没编译成功。唉~~ BT下载 ：utorrent。utorrent有linux版，但是web gui版。 虚拟机 ：virtualbox。在virtualbox装了xp，感觉比vmware快多了。。 日常应用 1.网络管理 ubuntu(包括linux mint)现在都是默认用NetworkManager来管理网络。我用了几次都不适应。这次立刻就把它卸载了，直接用脚本来管理网络。卸载命令： $ sudo apt-get --purge remove network-manager $ sudo apt-get --purge remove network-manager-gnome 然后就直接对/etc/network/interfaces和/etc/resolv.conf做修改，来配置网络了。 2.ADSL连接 寝室是用电信上网，如果不用路由拨号，就要自己电脑直接连到网口，自己拨号。 配置命令： $ sudo pppoeconf 在弹出的窗口中输入帐号和密码，注意之后有个提示选择是否开机时就自动拨号，如果不时总是直接连网口的，就不选吧。 配置完回到命令行，输入拨号命令就可以上网了： $ sudo pon dsl-provider 断开链接的命令则是： $ sudo pppoe-stop 3.连wifi http://www.jiangmiao.org/blog/1781.html 4.做AP，共享wifi http://blog.csdn.net/feifei454498130/article/details/6642140 5.截图 $ scrot -bst [ file ] 然后用鼠标框主目标即可。如果没有制定输出文件路径file，默认输出到用户主目录，并以时间命名。 2012.7.12 更新 找到一篇介绍自己只使用命令行经验的博文，好正点！ http://blog.chavezgu.com/2012/03/07/the-command-line-challenge/ 赞同里面循序渐进脱离GUI的方法； 坚持一天只使用命令行！ 坚持一周！！ 坚持一个月！！！ 坚持半年！！！！ 呵呵～～","tags":"linux","loc":"http://www.goorockey.com/blog/2012/02/29/zai-ci-yong-linuxzuo-su-zhu-xi-tong/","title":"再次用linux做宿主系统"},{"text":"ssh端口转发是什么 ssh端口转发也被叫ssh隧道，ssh代理。 所谓隧道，就是用X协议封装Y协议的数据包，靠X协议来进行Y协议通信。 总的来说ssh隧道提供了两个好处： 突破防火墙等，进行受限协议的通信。 使如telnet等不安全的协议传输经过ssh的加密通道，提高安全性。 三种ssh端口转发 ssh端口转发有三种： 本地转发 远程转发 动态转发 本地转发 命令是： $ ssh –L < local port>:<remote host>:<remote port> <ssh host> 考虑这样的场景： 一个运行在服务器116.1.1.1的程序提供端口389的数据通信，但防火墙只允许其他计算机对服务器做ssh的通信。 而客户端116.4.0.1为了完成通信，可以借助ssh的本地端口转发。 在客户端执行： $ ssh –L 7001:localhost:389 116.1.1.1 同时把客户端程序输出到本机的7001端口。注意命令中的localhost是相对于116.1.1.1来说的。 那么整个数据流会是： 客户端程序到数据输出到客户端的7001口 客户端的ssh一直检测7001口，但发现本机有数据包到达，则把数据包加密，并通过跟服务端116.1.1.1的ssh通路传输 服务端的sshd收到数据包后包解密，并转发到服务端的389口 服务端返回数据，并原路返回 另外，在ssh本地转发命令中的remote host可以使任意的机子，包括本机或其他计算机。 例如，考虑这样的场景，用本地转发来进行远程桌面： 现在要在机子A对机子C做远程桌面。但机子A和机子C都在不同的子网，不能直接通信，也都只能跟机子B用ssh通信。 然后已知windows远程桌面的服务端端口是3389，这我们可以在机子A执行： $ ssh –L 13389:<C hostname>:3389 <B hostname> 命令中的13389是任意的，但要注意只有管理员才能用1~1024的端口。 然后在A机子执行yuan远程桌面： mstsc /v:13389 就能在A机子远程桌面控制C机子了。 远程转发 其实远程转发跟本地转发是基本相同的。 命令是： $ ssh –R < local port>:<remote host>:<remote port> <ssh host> 考虑这样的场景： 客户端A和服务端B的端口都还是7001和389。 跟本地转发时候不同的是，ssh连接的sshd在客户端A，ssh在服务端B。 所以，远程转发可以应用在客户端A只允许对其做ssh连接的时候。 如果客户端和服务端都允许ssh连接，那选择本地转发还是远程转发都可以。 动态转发 命令是： $ ssh –D < local port> <ssh host> 跟其他两种端口转发不同的是，动态转发在数据包经过ssh通过到达服务端后，sshd会根据把封装数据包的协议，转发到对应的主机和端口。 这时候ssh隧道是充当了SOCKS代理的作用。这就可以用来翻X之类了。 Ending 总的来说，ssh是个好东西~~~ 相关资料： https://www.ibm.com/developerworks/cn/linux/l-cn-sshforward/ http://lesca.me/blog/2011/03/01/ssh-port-forwarding-priciple-and-praticle-application/","tags":"network","loc":"http://www.goorockey.com/blog/2012/02/22/sshduan-kou-zhuan-fa/","title":"SSH端口转发"},{"text":"之前在sourceforge搭建了wordpress，但SF有两点不好： SF在防火墙禁止了对外连接，使得WP好多功能、插件都无法使用（如Akismet） 访问SF速度很慢很慢 之后在寻找更好的方案时，偶遇dotcloud上搭建wordpress的文章，还看到了借dotcloud的ssh来翻x哦。 dotcloud介绍 dotcloud是PaaS(Platform as a Service)的云计算平台，类似的还有GAE、Heroku、国内的SAE。 dotcloud支持几乎所有主流服务，php、java、python、ruby、mysql、postsql、node.js、Hadoop等等。详细参见： http://docs.dotcloud.com/firststeps/platform-overview/ dotcloud对搭建的应用没有空间和流量限制，但现在有两个限制： 每个用户只能有两个应用（每个用户对应一个邮箱，有多个邮箱就可以多申请几个了嘛，呵呵） 网上流传数据库容量限制在10M（官网上没找到这个说法） dotcloud的访问速度还是很快的。 dotcloud使用 搭建wordpress的话，网上资源很多，我主要是参考： http://blog.yangtse.me/2011/10/wordpress-dotcloud/ http://olddocs.dotcloud.com/tutorials/wordpress/ 反正算蛮简单的。 建议： 不要用postinstall脚本连接的方法。由于dotcloud的push，是把原有的全部删除，重新建立一份，这个脚本是把wp-content移出current目录，防止push后把wp-content覆盖了。 但由于wordpress的bug（其他应用不确定），一些插件会出现路径的错误。例子可见： http://blog.yangtse.me/2011/10/wordpress-dotcloud-habari-error/ dotcloud的push我除了第一次上传代码用过，之后都是直接用ssh控制的。所以我就干脆不用postinstall脚本了。","tags":"blog","loc":"http://www.goorockey.com/blog/2012/02/07/zai-dotcloudshang-da-jian-wordpress/","title":"在dotcloud上搭建wordpress"},{"text":"今天拿自己项目组svn的日志来小玩了一下code swarm。 什么是code swarm? code swarm是可以把svn、cvs、git等代码管理系统的日志，以可视化的形式展现的项目。 swarm是蜂群的意思，code swarm会以蜂群的形式表示每个人上传的文件。 很多大的项目，如Apache、Python、豆瓣等，都做了自己的code swarm。 Apache、Python等： http://www.michaelogawa.com/code_swarm 豆瓣： http://v.youku.com/v_show/id_XMzQzNDc4MDk2.html 我个人感觉，看别人的code swarm没什么特别的感受，只有看自己项目的才有感觉，呵呵。 使用 code swarm 可以从它google code 的主页中下载代码： http://code.google.com/p/codeswarm/downloads/list 我参照别人博客，使用了code swarm别的fork： https://github.com/rictic/code_swarm ，它可以显示每个人的头像。 根据wiki或下载包内的README，使用code swarm，要先安装java和ant。 code swarm有可以通过run.bat或者runrepositoryfetch.bat来启动。run.bat需要我们手工把svn等软件的日志转为code swarm所需的xml，而runrepositoryfetch.bat可以输入reposition url，让code swarm自动下载日志并转换。我选择简单的runrepositoryfetch.bat方式。 在命令行提示中选择配置文件后，code swarm就能呈现了，但还可以修改配置来达到自己的效果。 配置code swarm 我觉得关键的配置： InputFile code swarm所需的xml文件 TakeSnapshots 是否保存每一帧图片。code swarm不能直接输出视频，只能输出每一帧图片。所以我们要导出视频的话，需要自行把每一帧图片转换为视频。 SnapshotLocation 保存输出图片的目录 还有一些控制帧速度，显示项等等的配置。 以下是fork中才有的配置： AvatarFetcher 每个人使用头像的来源。可以是NoAvatar（没有头像），GravatarFetcher（程序自己生成），LocalAvatar（提供本地目录，使用跟commiter id对应的头像）。 LocalAvatarDirectory LocalAvatar方式时，存放头像的目录，目录里如果有文件名与commiter id相同的图片，则使用该图片否则使用默认头像。如果没有默认头像，则程序会中断。 LocalAvatarDefaultPic 默认头像 AvatarSize 选择LocalAvatar方式时，每张头像的高或宽。这里要求每张头像图片的尺寸相同，且一定是正方形。 CircularAvatars 用圆形截取头像图片，这会用到程序代码src下的mask.png图片，这里也要注意修改AvatarSize后，mask.png的尺寸也要改变，否则程序中断。 把code swarm的图片合成为视频 方法很多，抱着学习的心态，我试着按wiki的方法用mencoder。 我要加背景音乐，所以加了参数-audiofile： mencoder mf://*.png -mf fps=33:type=png -ovc lavc -oac copy –audiofile bg.mp3 -o my.avi 这里可以通过修改fps的值来控制生成视频的帧速度。 还可以用mencoder添加字幕，这个我就没做了。 我的视频： http://v.youku.com/v_show/id_XMzQ4NjA5ODYw.html P.S.相关资料 【code swarm wiki】 ： http://code.google.com/p/codeswarm/wiki/GeneratingAVideo 【fork of code swarm】： https://github.com/rictic/code_swarm 【制作code swarm】： http://blog.xupeng.me/2012/01/12/code-swarm/ 【用mencoder把多张图片合成为视频】： http://www.mplayerhq.hu/DOCS/HTML/en/menc-feat-enc-images.html 【使用mencoder】： http://hi.baidu.com/creatives/blog/item/41f6c32ad06cdb2bd42af128.html 【windows下安装mencoder】： http://hi.baidu.com/%D7%AF%D7%D3%C8%E7%CA%C7%CB%B5/blog/item/611a28b11abebd5f0823021b.html","tags":"others","loc":"http://www.goorockey.com/blog/2012/02/03/code-swarm/","title":"Code Swarm"},{"text":"这几天把博客从GAE+micolog转到了sourceforge+wordpress，主要是考虑到： 服务器：GAE现在对流量加大了限制，而sourceforge是没有流量或空间限制的 博客系统：wordpress的资源币micolog的要多很多 主要做了几件事： sourceforge+wordpress建站 micolog数据导入到wordpress 优化wordpress：主题、插件、google analytics 考虑到SEO的域名权重问题，就保留sourceforge的二级域名了。 教程的话网上资源很多，值得记录的东西： 安装wordpress，及其主题、插件等资源时，最好用ssh登录到sourceforge，从sourceforge那边wget下载，而不要从自己机子下载。因为资源多在国外的服务器，这样速度快多了。 注意关闭sourceforge项目管理中不必要的访问权限，以免博客里的文件被在sourceforge中能被访问。 感叹sourceforge真是太伟大了！ 感叹wordpress真的就两个字：折腾！！ 2012.1.29 更新： 昨天还发现github+octopress这种免费建博客的形式。 但建的是静态站点，即服务器存放的就只是html+css+js网页,没有php、asp等。 优点： 最重要的优点是git的分布式管理，保证博文等数据不容易丢失； git的其他各种优点 静态站点的优点：响应速度快，对服务器端的负荷小 缺点: 我觉得缺点主要是静态站点的后期维护成本高！ 因为到了后期，文章等数据多了，服务器就会存有大量网页，大大增加修改、备份等维护的成本！！ 折腾octopress的成本。octopress的官网说其是\"a blog framework for HACKERS \"，本身是ruby应用，即折腾它要玩ruby。要折腾octopress似乎比较适合程序猿。（ruby折腾迷略过此条。。） 考虑到静态站点的后期维护问题，我觉得还是SF+WP比较适合现在的我啦~~嘻嘻 2012.2.5 更新： 根据SF的官方规定，架在上面的服务的outbound connection会被禁止。详细请参看： http://sourceforge.net/apps/trac/sourceforge/wiki/Project%20web%20and%20developer%20web%20platform#Outboundconnectivity 而因为很多WP的功能、插件等都会用到向外发送请求，所以在SF上架WP的时候，很多功能和插件都用不了的。 例如，WP内置的更新ping服务器，Akismet， google sitemap，微博同步等等。。 现在还没找到什么办法，唉。。","tags":"blog","loc":"http://www.goorockey.com/blog/2012/01/28/bo-ke-zhuan-yi-liao-gai-yong-sourceforgewordpress/","title":"博客转移了（改用sourceforge+wordpress）"},{"text":"调研了一下Apache和Tomcat： 1.apache 只是一个web服务器，负责响应客户端的请求。 2.apache对于页面请求： 如果是静态页面请求，会立刻返回相应的页面； 如果是动态页面请求，apache会根据httpd.conf中AddType的配置，把请求提交给合适的动态脚本解析程序来处理，处理后生成的静态页面返回给apache，再返回给客户端。所以在配置php和jsp这样的环境的时候，都要在httd.conf中添加对应的AddTpye语句。 3.tomcat侧重于是一个Servlet/JSP的容器，但也能可以独立于apache运行，响应html请求 4.tomcat响应静态页面较apache要慢 5.整合apache和tomcat可以有三种方法:JK,http_proxy,ajp_proxy 具体介绍见： http://www.ibm.com/developerworks/cn/opensource/os-lo-apache-tomcat JK较老，相对比较稳定，配置比较麻烦 两种proxy模式原理都是让apache做tomcat的代理，配置简单","tags":"linux","loc":"http://www.goorockey.com/blog/2011/11/22/apachehe-tomcat/","title":"Apache和Tomcat"},{"text":"一、安装及配置Apache+php+mysql 1.安装Apache+php+mysql 安装Apache+php+Mysql，php连接mysql的组件 yum -y install httpd php mysql mysql-server php-mysql 安装mysql扩展 yum -y install mysql-connector-odbc mysql-devel libdbi-dbd-mysql 安装php的扩展 yum -y install php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc 安装apache扩展 yum -y install httpd-manual mod_ssl mod_perl mod_auth_mysql 或者一次性粘贴安装: yum -y install httpd php mysql mysql-server php-mysql httpd-manual mod_ssl mod_perl mod_auth_mysql php-mcrypt php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc mysql-connector-odbc mysql-devel libdbi-dbd-mysql 2.配置Apache+php+mysql 设置apache为自启动 chkconfig httpd on mysql服务 chkconfig –-add mysqld mysqld服务 chkconfig mysqld on 自启动 httpd 服务 service httpd start 自启动mysqld服务 service mysqld start 二、安装和配置Tomcat： 1.安装JDK： 为了默认使用Sun的javac作为Java的编译器，首先删除CentOS系统默认的Java编译器--gcj。 查看: [root@localhost ~ ]#rpm –qa |grep gcj java-1.5.0-gcj-1.5.0.0-29.1.el6.i686 libgcj-4.4.4-13.el6.i686 卸载 [root@localhost ~ ]#rpm –e java-1.5.0-gcj-1.5.0.0-29.1.el6.i686 --nodeps [root@localhost ~ ]#rpm –e libgcj-4.4.4-13.el6.i686 --nodeps 检测 [root@localhost ~]# java --version 会出现 -bash: /usr/bin/java: No such file or directory 表示卸载成功 安装jdk 从Jdk官网下载安装包，如: jdk-6u27-linux-i586-rpm.bin P.S. 由于我的CentOS没有图形界面，下载不方便， 我是先在Windows上访问JDK官网下载安装包， 然后再用Winscp传到CentOS的 比如安装包保存在/opt/tmp 跳到该目录添加可执行的权限，并执行 chmod 777 jdk-6u27-linux-i586-rpm.bin ./jdk-6u27-linux-i586-rpm.bin 添加环境变量 vim /etc/profile 添加以下内容： export JAVA_HOME=/usr/java/jdk1.6.0_27 export JAVA_BIN=/usr/java/jdk1.6.0_27/bin export PATH= $ PATH : $ JAVA_HOME /bin export CLASSPATH=.: $ JAVA_HOME /lib/dt.jar: $ JAVA_HOME /lib/tools.jar 保存后，执行java -version 如果有类似以下显示，则表示安装成功： java version \"1.6.0_27\" 2.安装Tomcat： 从Tomcat官网下载 安装包，如：apache-tomcat-7.0.22.tar.gz 把该压缩包拷贝到/usr/local cp apache-tomcat-7.0.22.tar.gz /usr/local 跳转到/usr/local，并解压压缩包 cd /usr/local tar -zxvf apache-tomcat-7.0.22.tar.gz 把解压出来的目录改名为tomcat,并删除拷贝过来的压缩包 rm apache-tomcat-7.0.22 tomcat 执行/usr/local/tomcat/bin/startup.sh ，自动添加环境变量， 测试 访问 http://localhost:8080 ，出现tomcat默认页面，则表示tomcat安装成功 3.配置Tomcat为开机自启动： 添加开机daomon脚本 把/usr/local/tomcat/bin/catalina.sh拷贝到/etc/init.d，并命名为tomcat cp /usr/local/tomcat/bin/catalina.sh /etc/init.d/tomcat 在/etc/init.d/tomcat添加内容： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/bin/sh # chkconfig: 2345 10 90 # description:Tomcat service # Licensed to the Apache Software Foundation (ASF) under one or more …… # $Id: catalina.sh 1073891 2011-02-23 19:23:59Z markt $ # ------------------------------------------------------------------------ CATALINA_HOME = /opt/tomcat JAVA_HOME = /opt/jdk1.6.0_23 …… 添加tomcat服务 chkconfig --add tomcat service tomcat stop service tomcat start chkconfig tomcat on 搞定！！","tags":"linux","loc":"http://www.goorockey.com/blog/2011/11/12/centosxia-an-zhuang-apachephpmysql-tomcat/","title":"CentOS下安装Apache+php+mysql Tomcat"},{"text":"原子操作 能调用的原子操作 LONG InterlockedExchangeAdd(PLONG plAddend,LONG Increment); LONG InterlockedExchange(PLONG plTarget, LONG lValue); PVOID InterlockedExchangePointer(PVOID* ppvTarget, PVOID pvValue); PVOID InterlockedCompareExchange(PLONG plDestination, LONG lExchange, LONG lComparand); PVOID InterlockedCompareExchangePointer(PVOID* ppvDestination, PVOID pvExchange, PVOID pvComparand); 以查询方式同步 volatile BOOL g_fFinishedCalculation = FALSE; int WINAPI WinMain(…) { CreateThread(…, RecalcFunc, …); … //Wait for the recalculation to complete. while(!g_fFinishedCalculation); … } DWORD WINAPI RecalcFunc(PVOID pvParam) { //Perform the recalculation. … g_fFinishedCalculation = TRUE; return(0); } 查询的线程一直处于可调度状态，浪费CPU时间 如果WinMain的线程优先级比ReclcFunc的线程要高，则g_fFinishedCalculation永远不会被置为TRUE。 关键代码段Critical_Section 使用前调用InitializeCriticalSection进行初始化，使用后用DeleteCriticalSection释放资源 在指向同一个Critical_Section的EnterCriticalSection和LeaveCriticalSection之间的代码，不会被多个线程同时调用 同一个线程多次重入EnterCriticalSection和LeaveCriticalSection之间的代码不会发生死锁。 如下面代码不会有死锁： int main(int argc, char **argv) { CRITICAL_SECTION cs; InitializeCriticalSection(&cs); EnterCriticalSection(&cs); EnterCriticalSection(&cs); while(1) { cout << \"testing\" << endl; } LeaveCriticalSection(&cs); LeaveCriticalSection(&cs); return 0; } 考虑到线程进入等待状态时，要保护现场，这是非常耗时的。这可以用InitializeCriticalSectionAndSpinCount，它让想进入已被占用的关键代码段的线程先循环判断多次，才进入等待状态。 InitializeCriticalSectionAndSpinCount只对多个CPU起作用，单个CPU不起作用。 SetCriticalSectionSpinCount可以改变循环判断的次数 关键代码段是在用户态实现同步的方法，这样比内核态同步要快，因为不用做用户态和内核态之间的往返（往返一次需要占用x 8 6平台上的大约1 0 0 0个C P U周期）。 内核对象同步 当内核对象是自动设置为有信号时，在所有等待该内核对象的线程中，只会有一个变为可调度，然后该内核对象又自动设为无信号。 当内核对象是手动设置为有信号时，除非手动设置该内核对象的状态，否则一直是有信号，这样所有等待该内核对象的线程都能变为可调度。 WaitableTimer WaitableTimer能在规定时候或按规定的时间间隔变为有信号状态，就类似闹钟。 SetWaitableTimer设置开始定时的时间（如果传参是负数，则是相对于这个函数被调用的时间）、定时的间隔、定时间隔到时调用的函数 CancelWaitableTimer取消WaitableTimer的定时。 其他等待函数 --- | --- MsgWaitForMultipleObjects和MsgWaitForMultipleObjectsEx | 等待多个内核对象有信号、或指定类型消息到达线程的输入队列 SingleObjectAndWait | 在一个原子操作完成设置一个内核对象为有信号，并进入等待另一个内核对象 各同步的内核对象的理解 关键代码段: critical section ,关键代码段之间的代码是原子操作，同一时间只能有一个线程执行该段代码，与别的同步object都是内核态的同步相比，它争取用用户态的方式进行同步，如果用户态的用户不行，才用内核态的同步，这样效率更高,花费较少 锁: mutex，只允许一个线程拥有 semaphore，允许指定数量的线程拥有，创建此object时可以指定能拥有的最多的线程数 信号： event，不同于锁，就如它的名字是\"信号\"，当一个线程拥有锁的时候就会改变锁的状态以达到同步（`成功拥有mutex则使它无信号；成功拥有semaphore则使它计数减一，当计数为零，则semaphore变成无信号状态），手动设置的event的状态只有线程调用SetEvent或ResetEvent才会改变，线程则通过WaitForSingleObject等检测信号状态的函数来达到同步。","tags":"windows","loc":"http://www.goorockey.com/blog/2011/09/05/windowshe-xin-bian-cheng-du-shu-bi-ji-3-xian-cheng-tong-bu/","title":"《Windows核心编程》读书笔记3--线程同步"},{"text":"一、摘要： 进程只是线程的容器，存放数据和代码，但不执行代码。 线程才是执行代码的实体。 作业是对一个或多个进程的统一管理，能添加一般无法添加的限制。 二、进程 1.概念 进程只是线程的容器 ，为线程执行代码提供资源、营造运行环境。 2.进程的构成 关键： 一块内存地址空间，用以存放代码和数据； 一个内核对象句柄表，记录使用中的内核对象。 更详尽的构成 (来自MSDN http://msdn.microsoft.com/zh-cn/library/ms681917(v=vs.85).aspx ): a virtual address space, executable code, open handles to system objects, a security context, a unique process identifier, environment variables, a priority class, minimum and maximum working set sizes, at least one thread of execution. 3.进程的终止 全部线程都结束。即使主线程退出了，如果还有线程存在，该进程仍然不会销毁。 ExitProcess，有可能造成内存泄露，因为C/C++ Runtime Library没有被清空，则全局变量等资源就不会被释放。 TerminateProcess，跟ExitProcess一样是可能造成内存泄露的。另外它是异步的，即只是通知要终止目标进程，返回后并不代表它已结束。 三、作业 1.基本概念 作业是进程的容器 ，对一个或多个进程附加一定的限制，进行统一管理。 即使作业只包含了一个进程也是有用的，因为这样能做一些普通不能进行的限制 2.主要的API: API 功能 CreateJobObject 创建作业内核对象 OpenJobObject 根据Handle打开作业内核对象 IsProcessInJob 验证某一个进程是否存在于作业中 SetInformationJobObject 给作业加上各种限制 QueryInformationJobObject 查询作业对象的信息 AssignProcessToJobObject 将进程放入作业 TerminateJobObject 终止作业内所有进程 3.用于作业对象的基本用户界面限制的位标志 标志 描述 JOB_OBJECT_UILIMIT_EXITWINDOWS 用于防止进程通过ExitWindowsEx函数退出、关闭、重新引导或关闭系统电源 JOB_OBJECT_UILIMIT_READCLIPBOARD 防止进程读取剪贴板的内容 JOB_OBJECT_UILIMIT_WRITECLIPBOARD 防止进程删除剪贴板的内容 JOB_OBJECT_UILIMIT_SYSTEMPARAMETERS 防止进程通过SystemParametersInfor函数来改变系统参数 JOB_OBJECT_UILIMIT_DISPLAYSETTINGS 防止进程通过ChangeDisplaySettings函数来改变显示设置 JOB_OBJECT_UILIMIT_GLOBALATOMS 为作业赋予它自己的基本结构表，使作业中的进程只能访问该作业的表 JOB_OBJECT_UILIMIT_DESKTOP 防止进程使用CreateDesktop或SwitchDesktop函数创建或转换桌面 JOB_OBJECT_UILIMIT_HANDLES 防止作业中的进程使用同一作业外部的进程创建的USER对象（如HWND） 四、线程 1.基本概念 进程不执行代码的， 是线程在进程地址空间内执行代码 ，并对进程地址空间内的数据做操作。 多个线程共享进程内的地址空间，包括进程的内核对象句柄表，因为句柄表的存在依赖于进程，而不是线程。 2.线程的构成 关键： 一个堆栈、 一些用于保护线程的寄存器、 一个指令寄存器（IP）、 堆栈指针寄存器（SP） 更详尽的构成 （来自MSDN http://msdn.microsoft.com/zh-cn/library/ms681917(v=vs.85).aspx ）： All threads of a process share its virtual address space and system resources. In addition, each thread maintains exception handlers, a scheduling priority, thread local storage, a unique thread identifier, and a set of structures the system will use to save the thread context until it is scheduled. The thread context includes the thread's set of machine registers, the kernel stack, a thread environment block, and a user stack in the address space of the thread's process. Threads can also have their own security context, which can be used for impersonating clients. 3.线程的启动 初始化线程时会把 线程函数的入参(pvParam)、线程函数的指针(pfnStartAddrj) 压栈。 每个线程还有一个指令寄存器（IP）和堆栈指针寄存器（SP）。IP初始指向BaseThreadStart函数，它包含在Kernel32.dll中。 它主要是调用线程函数，并把函数返回值传给ExitThread： VOID BaseThreadStart(PTHREAD_START_ROUTINE pfnStartAddr,PVOID pvParam) { __try { ExitThread((pfnStartAddr)(pvParam)); } __except(UnhandledExceptionFilter(GetExceptionInformation())) { ExitProcess(GetExceptionCode()); } //NOTE: We never get here. } 之所以pfnStartAddr和pvParam压栈，就是因为线程开始运行时，CPU跳到IP指向BaseThreadStart，然后把pfnStartAddr和pvParam出栈，就把它们当做形参传给BaseThreadStart了。 五、其他 1.C/C++ Runtime Library的多线程版本 在C/C++ Runtime Library中，有一些全局变量。它们有可能同时被多个线程访问，使它们的值无法确定。 C/C++ Runtime Library为了适应多线程，出现多线程(MT)版本，改变一些全局变量和函数的特性。 主要思路是为每个线程关联一个数据结构 tiddata块 ，里面都有各全局变量对于这个线程的副本。即每个线程访问的是属于自己的\"全局变量\"，有属于自己的独立环境。 而相关的函数对这些全局变量的操作也会改为对于 tiddata块 对于值的操作。 例如： _beginthreadex就是在调用CreateThread来创建线程的基础上，在线程初始化时创建线程关联的**tiddata块**，并把这些全局变量拷贝到里面。所以_beginthreadex比CreateThread要安全。 _endthreadex则是对应多做了清空关联数据结构的操作。 如果在多线程版本的C/C++ Runtime Library中，用了CreateThread来创建线程，则线程初始化时不会有 tiddata块 。而当函数要访问 tiddata块 的时候，开始会访问失败，然后会自动生成一个，并把它与线程关联起来。但在一些情况下调用CreateThread就可能出现错误。 _beginthread比_beginthreadex、以及_endthread比_endthreadex的参数要少，少了对线程安全访问权的控制。 2.伪句柄 用GetCurrentThread和GetCurrentProcess得到句柄是自己句柄的引用，并不会使线程进程的使用计数加1，它们返回的句柄叫伪句柄。 用CloseHandle关闭伪句柄时，会返回FALSE。 3.纤程 UNIX服务器应用程序属于单线程程序（Windows定义），但其内部仿真了多线程工作。为了方便把UNIX服务器应用程序移植到Windows，就推出了纤程。 ConvertThreadToFiber 把线程转换为纤程。 纤程不应该返回，返回会使线程和该线程所有的纤程都撤销。 在单个线程里，每次只能运行一个纤程。可以用SwtichToFiber来切换纤程","tags":"windows","loc":"http://www.goorockey.com/blog/2011/09/03/windowshe-xin-bian-cheng-du-shu-bi-ji-2-jin-cheng-zuo-ye-xian-cheng/","title":"《Windows核心编程》读书笔记2--进程、作业、线程"},{"text":"一、摘要 1.内核对象有使用计数，当计数减为0时，内核对象被销毁。 2.内核对象有安全描述符，控制该进程能做的操作。 3.每个进程内有内核对象句柄表，记录使用中的内核对象。 二、内核对象 1.对内核对象的操作,只能通过调API 应用程序无法在内存中找到表示内核对象的数据结构,也就无法直接修改其状态。 要对内核对象操作，只能先获得其句柄，然后调用window定义好的API 2.内核对象的使用计数，记录在使用它的进程数 内核对象是属于内核的，而不属于任何一个进程，包括创建它的哪个进程。 内核对象中有一个使用计数的数据，记录在使用它的进程数。 只有当使用计数为零时，该内核对象才会被销毁。 即使创建它的进程终止了，该内核对象的使用计数不为零就不会被销毁。 3.内核对象的安全描述符，控制进程对其的使用权 在创建内核对象的API中，都有一个\"安全描述符\"的参数，是用来控制对这个内核对象的使用权的 例如创建文件内存映射CreateFileMapping就有一个PSECURITY_ATTRIBUTES的参数。 而在获取该内核对象的API OpenFileMapping中，会有一个表征获取该对象做什么操作的参数。 如果该用户允许对该内核对象做该操作，则成功返回该内核对象句柄，否则返回NULL 分辨一个对象是否为内核对象的标志是，创建该对象的API是否有\"安全描述符\"这个参数。 如创建GDI就没有该参数，所以GDI不是内核对象 4.进程的内核对象句柄表，记录使用的内核对象 内核对象句柄表结构： 索引 (Handle) 内核对象内存块的指针 访问屏蔽（标志位的DWORD） 继承标志（标志位的DWORD ） 1 0 x ? ? ? ? ? ? ? ? 0 x ? ? ? ? ? ? ? ? 0 x ? ? ? ? ? ? ? ? 2 0 x ? ? ? ? ? ? ? ? 0 x ? ? ? ? ? ? ? ? 0 x ? ? ? ? ? ? ? ? … … … … 每个进程内都有一个内核对象句柄表来记录它在使用的内核对象，表中包含该内核对象内存块的指针。 在内核对象的句柄就是该内核对象在此表中的索引值。 创建内核对象时，会在表中寻找空白项，并添加新项，并通过该内核对象指针对它的使用计数置1. 用CloseHandle释放进程对该内核对象使用权时，就通过该指针对使用计数减1 即使没有用CloseHandle，当进程终止时，会对句柄表中没有释放使用权的内核对象计数减1 5.进程间访问内核对象 设置子进程继承父进程的内核对象 创建有名字的内核对象，并通过内核对象名字访问它。 DuplicateHandle 复制内核对象 6.当用Create*（如CreateMutex）创建有名字的内核对象 如果 同名字 、 同类 的内核对象已存在，则返回该内核对象的Handle； 如果 同名字 、 不同类 的内核对象已存在，则创建失败，并返回NULL 如果没有同名字的内核对象存在，则创建新内核对象","tags":"windows","loc":"http://www.goorockey.com/blog/2011/09/02/windowshe-xin-bian-cheng-du-shu-bi-ji-1-nei-he-dui-xiang/","title":"《Windows核心编程》读书笔记1--内核对象"},{"text":"题一、有一个整数数组，请求出两两之差绝对值最小的值 方法：先排序，再找差值最小的点对。 效率：时间复杂度O(nlogn) 题二、平面上N个点，每两个点都确定一条直线，求出斜率最大的那条直线所通过的两个点（斜率不存在的情况不考虑） 方法：根据x排序，用图解枚举所有情况，能证明斜率最大的两点肯定是相邻的两点。 效率：时间复杂度O(nlogn) 题三、一棵排序二叉树，令 f=(最大值+最小值)/2，设计一个算法，找出距离f值最近、大于f值的结点 方法：把f插入，中序排序 效率：时间复杂度O(logn) 题四、找出两个字符串中最大公共子字符串 如\"abccade\",\"dgcadde\"的最大子串为\"cad\" 方法一： 从字符串一中遍历子串，并在字符串二中匹配。时间复杂度为O(n&#94;3)。 方法二： 矩阵法：用矩阵表示两字符串，横竖字符相同的格置1，则在45度方向连续1最多的就是所求，时间复杂度O(n&#94;2) 。 题五、检查单向链表中是否有环 这算是经典的面试题了，记录一下好的解法和推广。 方法一： 操作：把链表反向，当游标指针回到首节点时表示有环，否则无环。 解释：如果有环，把链表反向后，游标指针会从环内回到环外，最后回到首节点。 效率：时间复杂度O(n)，空间复杂度O(1)。 不足：破坏原链表的结构，需要再遍历一次链表来恢复链表结构。 方法二: 操作： 两个游标指针,一个慢指针每次移动一个节点，一个快指针每次移动两个节点。如果在快指针遍历到链表结尾前遇到慢指针，则链表有环，否则无环。 解释： 如果有环，当慢指针刚进入环时，设快指针与慢指针的距离为n（距离指慢指针不动是，快指针要经过几次节点达到慢指针），由于快指针每次都追上慢指针一个节点，则两者经过n次后总会相遇。 效率：时间复杂度O(n)， 空间复杂度O(1)。 [[ gist goorockey:3712175 ]] 推广一：有环单向链表中环的节点数 操作： 还是用快慢指针，当快慢指针在环内相遇后，两指针继续移动，并对慢指针移动的节点计数。当两指针再次相遇时，计数的结果就是环的节点数。 解释： 还是题一中的思想。设环的节点数为n，当两指针第一次相遇时，可看做两指针的距离为n，则再慢指针再经过n个节点后，两指针会再次相遇，所以慢指针移动的节点数就是环的节点数。 [[ gist goorockey:3712217 ]] 推广二、找到有环单向链表中环首节点 如以下有环单向链表： 1=>2=>3=>4=>5=>6=>7=>9=>4 即第9节点的next指针指向第4节点，则环的首节点为第4节点 操作： 先计算环的节点数n。 两个前后指针，前指针先移动n个节点，然后两指针一齐移动，每次都只移动一个的节点。 当两指针相遇时，两指针指向的节点就是所求的环首节点。 解释：因为开始两指针相距n个节点，当后指针刚进入环时，肯定会与前指针在环的首节点相遇。 推广三、破坏有环单向链表的环 操作： 在上面的基础上，当找到了环首节点和环内节点数n后，只要从环首节点移动n到达环的尾节点，修改环尾节点的next指针即可。 [[ gist goorockey:3712226 ]] 题五、找到有序链表的中位值 常规方法：遍历一次链表得到链表长度length，再遍历一次链表到length/2的位置即为中位值 更好的方法：用两个指针p1、p2，p1每次走两步，p2每次走一步，等到p1到链表尾时，p2所指即为中位值 [[ gist goorockey:3824662 ]]","tags":"programming","loc":"http://www.goorockey.com/blog/2011/08/24/mian-shi-qu-ti/","title":"面试趣题"},{"text":"两个正整数x、y，x是y的倍数，不用除法运算符实现x / y。 1、最简单的方法 循环用x减y，知道x等于0。 int Div( int x, int y ) { int result = 0; while ( x > y ) { x -= y; result++; } return result; } 时间复杂度 O(n) 2、用移位实现 与很多优化算法相似，用2次幂实现加速。 考虑到x是y的倍数，设x = y * k 因为我们可以用二进制表示任意整数，所以任意整数都可表示成2次幂的和，即： k = 2&#94;t1 + 2&#94;t2 + …. + 2&#94;tn; 所以有x = y * (2&#94;t1 + 2&#94;t2 + … + 2&#94;tn)，即我们要的结果就是2&#94;t1 + 2&#94;t2 + … + 2&#94;tn 由此，我们可以先找到一个刚好不大于x的s1 = y*(2&#94;t1)，即有 y*2&#94;t1 <= x < y*2&#94;(t1+1) , 然后令x2 = x - s1 = y * (2&#94;t2 + … + 2&#94;tn)，从而继续递归直到xn – sn = 0。 int Div( int x, int y ) { int i = 1; // 2次幂计数器 int product = y; // 中间乘积，等于y*2&#94;t，即product = y * i // 找到刚好不大于x的product = y*i满足y*i <= x < y*(i+1) while ( product << 1 <= x ) { i <<= 1; product <<= 1; } // 递归得到结果 int result = 0; for ( ; x > 0; i >>= 1, product >>= 1 ) { // product自除2来寻找新的product，满足刚好不大于x if ( x >= product ) { result += i; // 累加结果result = 2&#94;t1 + 2&#94;t2 … + 2&#94;t(k-1) x -= product; // 相减得到新的x = y*(2&#94;tk + … + 2&#94;tn) } } return result; } 时间复杂度 O(logn) 3、推广 - 不用开方运算符求幂数： 两个正整数x、y，不用开方运算符求x是y的几次幂。 思想与方法二类似。 #include \"math.h\" int Extract ( int x , int y ) { int i = 1 , power = y ; while ( power * power <= x ) { i <<= 1 ; power *= power ; } int result = 0 ; for ( ; x > 1 ; i >>= 1 , power /= pow ( y , i )) { if ( x >= power ) { x /= power ; result += i ; } } return result ; } 时间复杂度 O(logn)","tags":"programming","loc":"http://www.goorockey.com/blog/2011/08/22/bu-yong-chu-fa-yun-suan-fu-shi-xian-chu-fa-ji-qi-tui-yan/","title":"不用除法运算符实现除法及其推广"},{"text":"1.Reflect 对于WM_NOTIFY消息： 子控件没有Reflect，则由父窗口处理。 只要子控件（即消息对应最直接的控件）有了ON_NOTIFY_REFLECT就会被子控件处理,不会被父窗口所处理。 Reflect的意思就是把消息反射给子控件处理。 大概的就是这样： 子控件有ON_NOTIFY_REFLECT 父窗口有ON_NOTIFY 效果 WM_NOTIFY未被处理 WM_NOTIFY只被父窗口处理 WM_NOTIFY只被子控件处理 Y Y WM_NOTIFY只被子控件处理 2.EX ON_NOTIFY和ON_NOTIFY_EX 以及 ON_NOTIFY_REFLECT和ON_NOTIFY_REFLECT_EX 区别是： EX版本的处理函数有BOOL型返回值，表示处理的消息是否继续消息传递 返回TRUE，表示不继续； 返回FALSE，表示继续，即其他控件可以对它做处理。 则EX的意思就是把消息重新放到消息循环，继续遍历别的CmdTargetObject。 大概是这样： 子控件ON_NOTIFY_REFLECT_EX返回值 父窗口有ON_NOTIFY 效果 TRUE N WM_NOTIFY只被子控件处理 TRUE Y WM_NOTIFY只被子控件处理 FALSE N WM_NOTIFY只被子控件处理 FALSE Y WM_NOTIFY被子控件和父窗口处理","tags":"windows","loc":"http://www.goorockey.com/blog/2011/08/19/vczhong-dui-wm_notifyde-chu-li/","title":"VC中对WM_NOTIFY的处理"},{"text":"终于把Micolog搞到墙内了！ 用chrome打开速度很理想！ 稍微修改一下Windows Live Writer的设置也能直接连到博客了！ =======================兴奋的分割线=============================== 具体方法参考了： http://gae.v2find.tk/2011/06/23/micolog-gae-tk.html 但由于dot.tk对免费域名有限制： 在90天内少于25名用户访问时,免费域名会过期。 所以我改在 co.cc 申请免费域名。 操作跟dot.tk的对应，只是每次修改设置（如修改dns服务器）时并不一定立刻就生效，它也说了最多会在48小时内生效。 其他都按照链接的方法做就OK了。","tags":"blog","loc":"http://www.goorockey.com/blog/2011/08/15/zhong-yu-ba-bo-ke-gao-dao-qiang-nei-liao/","title":"终于把博客搞到墙内了！"},{"text":"自产生程序：不通过任何输入，输出自己代码的程序。 很多语言都可以写出这样的程序。 C版本(只有一行)： char s[] = \"char s[] = %c%s%c;int main(){ printf(s, 34, s, 34);return 0;}\";int main(){ printf(s, 34, s, 34);return 0;} 虽然是写出来了，但里面还是有很多值得研究的东西的。 参考资料： http://www.nyx.net/~gthompso/quine.htm","tags":"programming","loc":"http://www.goorockey.com/blog/2011/08/08/zi-chan-sheng-cheng-xu/","title":"自产生程序"},{"text":"经典的解法1: a += b; // a变成a+b b = a – b; // b变成原来的a，因为a+b-b = a a –= b; // a变成原来的b，因为a+b-a = b 存在的问题: a+b太大的话会溢出 经典的解法2: a &#94;= b; // a变成a&#94;b b &#94;= a; // b变成原来的a，因为b&#94;(a&#94;b) = a a &#94;= b; // a变成原来的b，因为a&#94;(a&#94;b) = b 存在的问题: a、b的值不能超过对方的位数所能表达的范围. 如下面这种情况就会出问题: int a = 0x10101010; // 设此时int为4个字节 short b = 0x15; 这个问题已经老生常谈了，不过今天还是遇到一个问题： 当两个要交换的数其实是同一个变量（更准确的说是同一个内存）时两种解法都会出错，变量被置0。 原因自己推算即可得出。 所以，我觉得更为保险的方法就是在交换之前先判断a、b是否相等，就既提高效率又防止出错。","tags":"programming","loc":"http://www.goorockey.com/blog/2011/08/06/xiao-ji-bu-yong-di-san-ge-bian-liang-jiao-huan-liang-shu/","title":"小记：不用第三个变量交换两数"},{"text":"1.普通的成员函数 编译器会自动为其添加一个 this指针 作为入参 该成员函数能修改成员变量 2.在成员函数后面加 const (注意是后面！) 编译器会自动为其添加一个 const *this指针 作为入参 该成员函数不能修改成员变量 3.成员函数加 static 编译器不会加 this指针 该成员函数不能直接访问成员变量，只能访问静态成员变量 所以在成员函数加 static 和后面加 const 是矛盾的，即不能同时这样修饰一个成员函数.","tags":"cpp","loc":"http://www.goorockey.com/blog/2011/08/02/bu-neng-tong-shi-yong-statiche-constxiu-shi-yi-ge-cheng-yuan-han-shu/","title":"不能同时用static和const修饰一个成员函数"},{"text":"#include <iostream> #include <iterator> #include <algorithm> int a [] = { 335 , 33 , 98 , 39 , 54 , 24 , 3 }; int nSize = sizeof ( a ) / sizeof ( a [ 0 ]); // 输出数组a到标准输出，同时每个元素都以空格为结束（最后一个元素后面也会有空格） std :: copy ( a , a + nSize , std :: ostream_iterator < int > ( std :: cout , \" \" )); 结果：335 33 98 39 54 24 3 一个字：妙！！(&#94;0&#94;)/","tags":"cpp","loc":"http://www.goorockey.com/blog/2011/08/02/stlzhong-yong-copyhe-ostream_iteratorshu-chu-yi-ge-shu-zu/","title":"STL中用copy和ostream_iterator输出一个数组"},{"text":"今天遇到个问题： 想要知道文章里面有多少个单词，要怎么做呢？ 直接用vim的命令 命令模式下按： g <Ctrl-g> 这样命令行上面就会显示全文总的和当前的：行列数、单词数、字节数。 如果是在visual模式，选中了部分内容再按 g<C-g> ，则显示选择部分的对应信息。 更多详见 :h g_ctrl-g 和 :h v_g_ctrl-g 巧用替换功能 1.统计字段 先来统计某个字段出现的次数，比如要统计vim,就是： :%s/vim//gn 然后命令行就会显示vim匹配的次数和匹配的行数了。。。(=0=)/ 好，解释一下： %s 全文匹配 g 匹配行内所有 n 只显示匹配数，不真正地匹配 对了，关键就在与参数 n 了，哟！！ 2.统计更多 好，来用s的匹配模式统计更多： 统计字符数 :%s/.//gn (. 指代字符) 统计单词数 :%s/i+//gn (i指代英文字母，i+就是一个或连续多个英文字母，所以就是单词了) 统计行数 :%s/&#94;//gn (&#94;指代每行第一个非空字符) 精确匹配单词(如vim) :%s/<vim>//gn (指代单词的开始，指代单词的结束) (~0~)/ vim真强大啊，掌声加鬼吼！！ 更多详见 :h count-items :h su :h search-pattern P.S. 由于我配置了set hlsearch，每次匹配完都会高亮匹配，直到下一次匹配。 想清除高亮，可以输入命令 :nohl","tags":"linux","loc":"http://www.goorockey.com/blog/2011/05/19/vimde-tong-ji-gong-neng/","title":"vim的统计功能"},{"text":"先下载并安装Live Writer 地址如下 For Xp: http://explore.live.com/windows-live-writer-xp For Other: http://explore.live.com/windows-live-writer?os=other 添加用户： 1.选择\"其他日志服务\" 2.设置博客地址、用户名和密码 用户名和密码是Micolog管理页面中设置的rpc用户和密码 3.设置博客的类型 推介选择WordPress 2.2+, 发布的URL就是 \"你的博客地址/rpc\" 4.之后，等它配置完成就可以用Live Writer写Micolog了：） 要注意的地方： 更改了博客主题后，要及时更新Live Writer的账户配置: 【日志】-【编辑日志设置】，选择\"更新账户配置\"。 设置自动保存和标题提醒: 【工具】-【选项】-【编辑】，勾选\"自动保存草稿间隔\" 再选择【首选项】标签，勾选\"发布前提醒我指定标签\" 添加Ping服务器 为了让新博文发布后能被人即时知道，可以设置Ping服务器 注意Ping服务器的添加是在精不在多，太多无谓的Ping服务器只会徒增博文发布的时间。 【工具】-【选项】-【Ping服务器】 以下是我的Ping服务器： http://www.feedsky.com/api/RPC2 http://ping.baidu.com/ping/RPC2 http://blogsearch.google.com/ping/RPC2 http://www.zhuaxia.com/rpc/server.php http://www.xianguo.com/xmlrpc/ping.php http://so.blog.qihoo.com/pingblog.html http://api.my.yahoo.com/RPC2 http://search.msn.com/docs/submit.aspx http://www.sogou.com/feedback/blogfeedback.php 由于GFW，使得无法直接连接appspot.com，我的话是用VPN来解决的。","tags":"blog","loc":"http://www.goorockey.com/blog/2011/05/17/shi-yong-windows-live-writerxie-micologbo-wen/","title":"使用Windows Live Writer写Micolog博文"}]}